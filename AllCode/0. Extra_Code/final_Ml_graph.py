# -*- coding: utf-8 -*-
"""
Created on Fri Feb  9 15:25:47 2024

@author: admin
"""

import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

# Confusion matrices data
confusion_matrices = {
    "Decision Tree": np.array([[4, 0, 0, 0, 0, 0, 0, 0],
                               [0, 2, 0, 0, 0, 0, 0, 0],
                               [0, 0, 20, 0, 1, 0, 0, 0],
                               [0, 0, 0, 2, 0, 0, 0, 0],
                               [0, 0, 1, 0, 0, 0, 0, 0],
                               [0, 0, 0, 0, 1, 5, 0, 0],
                               [0, 0, 0, 0, 0, 0, 5, 0],
                               [0, 0, 0, 1, 1, 0, 0, 2]]),
    "Random Forest": np.array([[4, 0, 0, 0, 0, 0, 0, 0],
                               [0, 1, 1, 0, 0, 0, 0, 0],
                               [0, 0, 21, 0, 0, 0, 0, 0],
                               [0, 0, 0, 2, 0, 0, 0, 0],
                               [0, 0, 1, 0, 0, 0, 0, 0],
                               [0, 0, 0, 0, 1, 5, 0, 0],
                               [0, 0, 0, 0, 0, 0, 5, 0],
                               [0, 0, 1, 1, 0, 0, 0, 2]]),
    "k-Nearest Neighbors": np.array([[4, 0, 0, 0, 0, 0, 0, 0],
                                      [0, 0, 2, 0, 0, 0, 0, 0],
                                      [0, 0, 21, 0, 0, 0, 0, 0],
                                      [0, 0, 0, 2, 0, 0, 0, 0],
                                      [0, 0, 1, 0, 0, 0, 0, 0],
                                      [0, 0, 2, 0, 0, 4, 0, 0],
                                      [0, 0, 0, 0, 0, 1, 4, 0],
                                      [0, 0, 1, 1, 0, 0, 0, 2]]),
    "Naive Bayes": np.array([[4, 0, 0, 0, 0, 0, 0, 0],
                              [0, 1, 0, 0, 0, 0, 1, 0],
                              [0, 0, 15, 0, 3, 0, 3, 0],
                              [0, 0, 0, 2, 0, 0, 0, 0],
                              [0, 0, 1, 0, 0, 0, 0, 0],
                              [0, 0, 0, 0, 1, 4, 1, 0],
                              [0, 0, 0, 0, 0, 0, 5, 0],
                              [0, 0, 1, 1, 0, 0, 0, 2]]),
    "SVM Linear": np.array([[4, 0, 0, 0, 0, 0, 0, 0],
                             [0, 2, 0, 0, 0, 0, 0, 0],
                             [1, 1, 18, 0, 0, 1, 0, 0],
                             [0, 0, 0, 2, 0, 0, 0, 0],
                             [0, 1, 0, 0, 0, 0, 0, 0],
                             [0, 0, 1, 0, 1, 4, 0, 0],
                             [0, 0, 0, 0, 0, 0, 5, 0],
                             [0, 0, 1, 0, 1, 0, 0, 2]]),
    "SVM Polynomial Degree 3": np.array([[0, 0, 4, 0, 0, 0, 0, 0],
                                          [0, 0, 2, 0, 0, 0, 0, 0],
                                          [0, 0, 21, 0, 0, 0, 0, 0],
                                          [0, 0, 2, 0, 0, 0, 0, 0],
                                          [0, 0, 1, 0, 0, 0, 0, 0],
                                          [0, 0, 6, 0, 0, 0, 0, 0],
                                          [0, 0, 5, 0, 0, 0, 0, 0],
                                          [0, 0, 4, 0, 0, 0, 0, 0]]),
    "SVM Polynomial Degree 4": np.array([[0, 0, 4, 0, 0, 0, 0, 0],
                                          [0, 0, 2, 0, 0, 0, 0, 0],
                                          [0, 0, 21, 0, 0, 0, 0, 0],
                                          [0, 0, 2, 0, 0, 0, 0, 0],
                                          [0, 0, 1, 0, 0, 0, 0, 0],
                                          [0, 0, 6, 0, 0, 0, 0, 0],
                                          [0, 0, 5, 0, 0, 0, 0, 0],
                                          [0, 0, 4, 0, 0, 0, 0, 0]]),
    "SVM RBF": np.array([[0, 0, 4, 0, 0, 0, 0, 0],
                          [0, 0, 2, 0, 0, 0, 0, 0],
                          [0, 0, 21, 0, 0, 0, 0, 0],
                          [0, 0, 2, 0, 0, 0, 0, 0],
                          [0, 0, 1, 0, 0, 0, 0, 0],
                          [0, 0, 6, 0, 0, 0, 0, 0],
                          [0, 0, 5, 0, 0, 0, 0, 0],
                          [0, 0, 4, 0, 0, 0, 0, 0]]),
    
  "XGBoost": np.array([[3, 0, 1, 0, 0, 0, 0, 0],
                         [0, 2, 0, 0, 0, 0, 0, 0],
                         [0, 0, 21, 0, 0, 0, 0, 0],
                         [0, 0, 0, 2, 0, 0, 0, 0],
                         [0, 0, 1, 0, 0, 0, 0, 0],
                         [0, 0, 0, 0, 1, 5, 0, 0],
                         [0, 0, 0, 0, 0, 0, 5, 0],
                         [0, 0, 0, 0, 0, 0, 0, 4]]),
    "LightGBM": np.array([[4, 0, 0, 0, 0, 0, 0, 0],
                          [0, 2, 0, 0, 0, 0, 0, 0],
                          [0, 0, 21, 0, 0, 0, 0, 0],
                          [0, 0, 0, 2, 0, 0, 0, 0],
                          [0, 0, 1, 0, 0, 0, 0, 0],
                          [0, 0, 0, 0, 1, 5, 0, 0],
                          [0, 0, 0, 0, 0, 0, 5, 0],
                          [0, 0, 0, 0, 0, 0, 0, 4]]),
    "SVM Sigmoid": np.array([[0, 0, 4, 0, 0, 0, 0, 0],
                             [0, 0, 2, 0, 0, 0, 0, 0],
                             [0, 0, 21, 0, 0, 0, 0, 0],
                             [0, 0, 2, 0, 0, 0, 0, 0],
                             [0, 0, 1, 0, 0, 0, 0, 0],
                             [0, 0, 6, 0, 0, 0, 0, 0],
                             [0, 0, 5, 0, 0, 0, 0, 0],
                             [0, 0, 4, 0, 0, 0, 0, 0]])
}

# Mapping of labels to their corresponding classes
label_map = {
    0: "adware",
    1: "backdoor",
    2: "benign",
    3: "downloader",
    4: "spyware",
    5: "trojan",
    6: "virus",
    7: "worm"
}

# Draw confusion matrix
def plot_confusion_matrix(cm, title):
    plt.figure(figsize=(8, 6))
    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)
    plt.title(title)
    plt.colorbar()
    tick_marks = np.arange(len(label_map))
    plt.xticks(tick_marks, [label_map[i] for i in range(len(label_map))], rotation=45)
    plt.yticks(tick_marks, [label_map[i] for i in range(len(label_map))])
    plt.tight_layout()
    plt.ylabel('Actual label')
    plt.xlabel('Predicted label')

# Plot confusion matrices
for clf_name, cm in confusion_matrices.items():
    plot_confusion_matrix(cm, f'Confusion Matrix for {clf_name}')

plt.show()

# %%

import matplotlib.pyplot as plt

# Classifier names
classifiers = [
    "Decision Tree",
    "Random Forest",
    "k-Nearest Neighbors",
    "Naive Bayes",
    "SVM Linear",
    "SVM Polynomial Degree 3",
    "SVM Polynomial Degree 4",
    "SVM RBF",
    "SVM Sigmoid",
    "XGBoost",
    "LightGBM"
]

# Evaluation metrics
accuracy = [
    0.8889, 0.8889, 0.8222, 0.7333, 0.8222, 0.4667, 0.4667, 0.4667, 0.4667, 0.8889, 0.9111
]
precision = [
    0.8274, 0.8177, 0.6556, 0.7561, 0.7500, 0.0583, 0.0583, 0.0583, 0.0583, 0.7803, 0.8225
]
recall = [
    0.7857, 0.7292, 0.6208, 0.6726, 0.7530, 0.1250, 0.1250, 0.1250, 0.1250, 0.7857, 0.7917
]
f1_score = [
    0.7910, 0.7470, 0.6197, 0.6737, 0.7284, 0.0795, 0.0795, 0.0795, 0.0795, 0.7632, 0.7913
]

# Plotting
x = range(len(classifiers))
width = 0.2

plt.figure(figsize=(12, 6))

plt.bar(x, accuracy, width, label='Accuracy')
plt.bar([i + width for i in x], precision, width, label='Precision')
plt.bar([i + width*2 for i in x], recall, width, label='Recall')
plt.bar([i + width*3 for i in x], f1_score, width, label='F1 Score')

plt.xlabel('Classifier')
plt.ylabel('Score')
plt.title('Evaluation Metrics by Classifier')
plt.xticks([i + width*1.5 for i in x], classifiers, rotation=45, ha='right')
plt.legend()

plt.tight_layout()
plt.show()
#%%
from sklearn.metrics import roc_curve, auc

# True positive rate (TPR) and False positive rate (FPR) for each classifier
roc_curves = {}
auc_scores = {}

for clf_name, cm in confusion_matrices.items():
    # Compute True Positive Rate (TPR) and False Positive Rate (FPR)
    tpr = []
    fpr = []
    for i in range(len(label_map)):
        tp = cm[i, i]
        fn = np.sum(cm[i, :]) - tp
        fp = np.sum(cm[:, i]) - tp
        tn = np.sum(cm) - tp - fn - fp

        tpr.append(tp / (tp + fn))
        fpr.append(fp / (fp + tn))
    
    # Calculate AUC
    roc_curves[clf_name] = (fpr, tpr)
    auc_scores[clf_name] = auc(fpr, tpr)

# Plot ROC curves
plt.figure(figsize=(10, 8))
for clf_name, (fpr, tpr) in roc_curves.items():
    plt.plot(fpr, tpr, label=f'{clf_name} (AUC = {auc_scores[clf_name]:.2f})')

plt.plot([0, 1], [0, 1], 'k--')  # Random classifier line
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc='lower right')
plt.grid(True)
plt.show()
