# -*- coding: utf-8 -*-
"""
Created on Thu Feb  8 19:09:31 2024

@author: admin
"""
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from xgboost import XGBClassifier
from lightgbm import LGBMClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix
from prettytable import PrettyTable
import matplotlib.pyplot as plt

# Initialize dictionaries to store evaluation metrics
accuracy_scores = {}
precision_scores = {}
recall_scores = {}
f1_scores = {}
conf_matrices = {}

# Load data and select only 80000 features
df = pd.read_csv('F:\Mini_malware_sample\merge_mal_ben/feature_vec_malware.csv').iloc[:, :80001]

# Separate features and labels
X = df.iloc[:, 2:]  # Starting from the 3rd column as features
y = df['family']

# Encode labels into numeric format
from sklearn.preprocessing import LabelEncoder
label_encoder = LabelEncoder()
y = label_encoder.fit_transform(y)

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
X_train= np.array(X_train)
# Initialize classifiers
classifiers = {
    "Decision Tree": DecisionTreeClassifier(random_state=42),
    "Random Forest": RandomForestClassifier(n_estimators=100, random_state=42),
    "XGBoost": XGBClassifier(objective='multi:softmax', random_state=42),
    "LightGBM": LGBMClassifier(random_state=42),
    "k-Nearest Neighbors": KNeighborsClassifier(),
    "Naive Bayes": GaussianNB(),
    "SVM": SVC(random_state=42)
}

# Initialize PrettyTable
result_table = PrettyTable()
result_table.field_names = ["Classifier", "Accuracy", "Precision", "Recall", "F1 Score"]

# Iterate through each classifier
for clf_name, classifier in classifiers.items():
    classifier.fit(X_train, y_train)
    predictions = classifier.predict(X_test)
    
    # Calculate evaluation metrics
    accuracy = accuracy_score(y_test, predictions)
    precision = precision_score(y_test, predictions, average='weighted')
    recall = recall_score(y_test, predictions, average='weighted')
    f1 = f1_score(y_test, predictions, average='weighted')
    
    # Add results to PrettyTable
    result_table.add_row([clf_name, accuracy, precision, recall, f1])

# Print PrettyTable
print(result_table)
# Plotting accuracy, precision, recall, and F1-score
plt.figure(figsize=(12, 6))

# Accuracy
plt.subplot(2, 2, 1)
plt.bar(classifiers.keys(), accuracy_scores.values(), color='blue')
plt.title('Accuracy')
plt.ylabel('Score')

# Precision
plt.subplot(2, 2, 2)
plt.bar(classifiers.keys(), precision_scores.values(), color='green')
plt.title('Precision')
plt.ylabel('Score')

# Recall
plt.subplot(2, 2, 3)
plt.bar(classifiers.keys(), recall_scores.values(), color='orange')
plt.title('Recall')
plt.ylabel('Score')

# F1 Score
plt.subplot(2, 2, 4)
plt.bar(classifiers.keys(), f1_scores.values(), color='red')
plt.title('F1 Score')
plt.ylabel('Score')

plt.tight_layout()
plt.show()
