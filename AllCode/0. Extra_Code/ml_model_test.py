# -*- coding: utf-8 -*-
"""
Created on Mon Jan 29 20:17:27 2024

@author: Admin
"""
#pip install pandas scikit-learn xgboost

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
from sklearn.metrics import accuracy_score, classification_report

# Assuming 'data.csv' is the file containing the provided CSV data
df = pd.read_csv('data.csv')

# Separate features (X) and labels (y)
X = df.iloc[:, 2:]  # Starting from the 3rd column as features
y = df['family']

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Random Forest Classifier
rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)
rf_classifier.fit(X_train, y_train)
rf_predictions = rf_classifier.predict(X_test)

# XGBoost Classifier
xgb_classifier = XGBClassifier(objective='multi:softmax', random_state=42)
xgb_classifier.fit(X_train, y_train)
xgb_predictions = xgb_classifier.predict(X_test)

# Evaluate the models
print("Random Forest Classifier:")
print("Accuracy:", accuracy_score(y_test, rf_predictions))
print("Classification Report:")
print(classification_report(y_test, rf_predictions))

print("\nXGBoost Classifier:")
print("Accuracy:", accuracy_score(y_test, xgb_predictions))
print("Classification Report:")
print(classification_report(y_test, xgb_predictions))
