# -*- coding: utf-8 -*-
"""
Created on Sat Jan 20 11:57:52 2024

@author: BISHWAJIT
"""

import numpy as np
import os
import json
import re
import hashlib
import logging



from gensim.models import Word2Vec
# Hashing Trick Encoder
from sklearn.feature_extraction import FeatureHasher

# Similarity Encoder
from dirty_cat import SimilarityEncoder
#!pip install dirty_cat

import pickle
# import enchant 
# !pip install enchant

# !pip install gensim
# !pip install dataclasses
# !pip install dirty_cat
# dictionary to contain string pdrui info

# In[275]:


class FeatureType(object):
    ''' Base class from which each feature type may inherit '''

    name = ''
    dim = 0

    def __repr__(self):
        return '{}({})'.format(self.name, self.dim)

    def raw_features(self, input_dict):
        ''' Generate a JSON-able representation of the file '''
        raise (NotImplemented)

    def process_features(self, raw_obj):
        ''' Generate a feature vector from the raw features '''
        raise (NotImplemented)

    def feature_vector(self, input_dict):
        ''' Directly calculate the feature vector from the sample itself. This should only be implemented differently
        if there are significant speedups to be gained from combining the two functions. '''
        return self.process_raw_features(self.raw_features(input_dict))


# In[276]:

calls_of_api_rcv = []
class APIName(FeatureType):
    ''' api_name hash info '''

    name = 'api_name'
    dim = 32

    def __init__(self):
        super(FeatureType, self).__init__()
        self.encoder = Word2Vec.load(r'C:\Users\ashish\Desktop\DMalNet-main\DMalNet-main\encoder\skip-gram_previous.model')
        self.feature = np.zeros((32,), dtype=np.float32)

    def raw_features(self, input_dict):
        """
        input_dict: string
        """
        try:
            calls_of_api_rcv.append(input_dict)
            self.feature = self.encoder.wv[input_dict]
        except:
            print("api %s is not in the corpus " % input_dict )
            logging.error("api %s is not in the corpus" % input_dict)
        return self.feature

    def process_raw_features(self, raw_obj):
        return raw_obj


# In[277]:


class ArgIntInfo(FeatureType):
    ''' int hash info '''

    name = 'int'
    dim = 16

    def __init__(self):
        super(FeatureType, self).__init__()

    def raw_features(self, input_dict):
        hasher = FeatureHasher(self.dim).transform([input_dict]).toarray()[0]
        return hasher

    def process_raw_features(self, raw_obj):
        return raw_obj


# In[278]:

arg_string_dictionary_pdr = {}
reg_encoder_entries = []
paths_encoder_entries = []
dll_encoder_entries = []
url_encoder_entries = []
ip_encoder_entries = []


class ArgPDRUIInfo(FeatureType):
    ''' Path, Dlls, Registry, Urls, IPs similarity encoding '''

    name = 'pdrui'
    dim = 16 + 16 + 16 + 16 + 16

    def __init__(self):
        super(FeatureType, self).__init__()
        self._paths = re.compile('^c:\\\\', re.IGNORECASE)
        self._dlls = re.compile('.+\.dll$', re.IGNORECASE)
        self._urls = re.compile('^https?://(.+?)[/|\s|:]', re.IGNORECASE)
        self._registry = re.compile('^HKEY_')
        self._ips = re.compile('^((2(5[0-5]|[0-4]\d))|[0-1]?\d{1,2})(\.((2(5[0-5]|[0-4]\d))|[0-1]?\d{1,2})){3}$')
        with open("C:\\Users\\ashish\\Desktop\\DMalNet-main\\DMalNet-main\\encoder\\paths_sim.pkl", 'rb') as file:
            self.paths_encoder = pickle.loads(file.read())
            print(self.paths_encoder.categories_)
            paths_encoder_entries.append(self.paths_encoder.categories_)
        with open("C:\\Users\\ashish\\Desktop\\DMalNet-main\\DMalNet-main\\encoder\\dlls_sim.pkl", 'rb') as file:
            self.dlls_encoder = pickle.loads(file.read())
            print(self.dlls_encoder.categories_)
            dll_encoder_entries.append(self.dlls_encoder.categories_)
        with open("C:\\Users\\ashish\\Desktop\\DMalNet-main\\DMalNet-main\\encoder\\registry_sim.pkl", 'rb') as file:
            self.registry_encoder = pickle.loads(file.read())
            #print(registry_encoder.categories_)
            reg_encoder_entries.append(self.registry_encoder.categories_)
        with open(r"C:\Users\ashish\Desktop\DMalNet-main\DMalNet-main\encoder\urls_sim.pkl", 'rb') as file:
            self.urls_encoder = pickle.loads(file.read())
            url_encoder_entries.append(self.urls_encoder.categories_)
        with open("C:\\Users\\ashish\\Desktop\\DMalNet-main\\DMalNet-main\\encoder\\ips_sim.pkl", 'rb') as file:
            self.ips_encoder = pickle.loads(file.read())
            ip_encoder_entries.append(self.ips_encoder.categories_)

    def levenshtein_dist(str1, str2):
        len1, len2 = len(str1), len(str2)
        
        # Create a matrix to store the distances between substrings
        matrix = [[0] * (len2 + 1) for _ in range(len1 + 1)]
        
        # Initialize the first row and column of the matrix
        for i in range(len1 + 1):
            matrix[i][0] = i
        for j in range(len2 + 1):
            matrix[0][j] = j
        
        # Populate the matrix
        for i in range(1, len1 + 1):
            for j in range(1, len2 + 1):
                cost = 0 if str1[i - 1] == str2[j - 1] else 1
                matrix[i][j] = min(
                    matrix[i - 1][j] + 1,        # Deletion
                    matrix[i][j - 1] + 1,        # Insertion
                    matrix[i - 1][j - 1] + cost  # Substitution
                )
        
        # The final value in the matrix is the Levenshtein distance
        return matrix[len1][len2]
    
    def raw_features(self, input_dict):
        print("the input dict item is:", input_dict)
        arg_string_dictionary_pdr = input_dict.copy()
        paths_feature = np.zeros((16,), dtype=np.float32)
        dlls_feature = np.zeros((16,), dtype=np.float32)
        registry_feature = np.zeros((16,), dtype=np.float32)
        urls_feature = np.zeros((16,), dtype=np.float32)
        ips_feature = np.zeros((16,), dtype=np.float32)
        for str_name, str_value in input_dict.items():
            #print("the value is" + str_value)
            #print(str_value)
            if self._dlls.match(str_value):
                dll = re.split('\\\\', str_value)[-1]
                #print(type(dll))
                max_value = -1
                #print("the length of the dll enries is:" , str(len(dll_encoder_entries[0][0])))
                for y in range(0,16):
                    #print("the value of y is", str(y))
                    #print(dll)
                    #sim_large = self.levenshtein_dist(dll,dll_encoder_entries[0][0][y])
                    
                    
                    len1, len2 = len(dll), len(dll_encoder_entries[0][0][y])
        
       
                    matrix = [[0] * (len2 + 1) for _ in range(len1 + 1)]
        
                    # Initialize the first row and column of the matrix
                    for i in range(len1 + 1):
                        matrix[i][0] = i
                    for j in range(len2 + 1):
                        matrix[0][j] = j
        
                    # Populate the matrix
                    for i in range(1, len1 + 1):
                        for j in range(1, len2 + 1):
                            cost = 0 if dll[i - 1] == dll_encoder_entries[0][0][y][j - 1] else 1
                            matrix[i][j] = min(
                                matrix[i - 1][j] + 1,        # Deletion
                                matrix[i][j - 1] + 1,        # Insertion
                                matrix[i - 1][j - 1] + cost  # Substitution
                            )
                    sim_large = matrix[len1][len2]
                    
                    
                    if(sim_large > max_value):
                        max_value = sim_large
                #print(max_value)
                #similarity = Levenshtein.ratio(str_value, self._registry_similar_string)
                transfor_sim_bin = '{0:016b}'.format(max_value)
                #print(transfor_sim_bin)
                for j in range(0,len(transfor_sim_bin)):
                    dlls_feature[j] = transfor_sim_bin[j]
            if self._paths.match(str_value):
                max_value = -1
                for y in range(0,len(paths_encoder_entries[0][0])):
                    len1, len2 = len(str_value), len(paths_encoder_entries[0][0][y])
        
       
                    matrix = [[0] * (len2 + 1) for _ in range(len1 + 1)]
        
                    # Initialize the first row and column of the matrix
                    for i in range(len1 + 1):
                        matrix[i][0] = i
                    for j in range(len2 + 1):
                        matrix[0][j] = j
        
                    # Populate the matrix
                    for i in range(1, len1 + 1):
                        for j in range(1, len2 + 1):
                            cost = 0 if str_value[i - 1] == paths_encoder_entries[0][0][y][j - 1] else 1
                            matrix[i][j] = min(
                                matrix[i - 1][j] + 1,        # Deletion
                                matrix[i][j - 1] + 1,        # Insertion
                                matrix[i - 1][j - 1] + cost  # Substitution
                            )
                    sim_large = matrix[len1][len2]
                    if(sim_large > max_value):
                        max_value = sim_large
                #print(max_value)
                #similarity = Levenshtein.ratio(str_value, self._registry_similar_string)
                transfor_sim_bin = '{0:016b}'.format(max_value)
                #print(transfor_sim_bin)
                for j in range(0,len(transfor_sim_bin)):
                    paths_feature[j] = transfor_sim_bin[j]
            elif self._registry.match(str_value):
                max_value = -1
                for y in range(0,len(reg_encoder_entries[0][0])):
                    len1, len2 = len(str_value), len(reg_encoder_entries[0][0][y])
        
       
                    matrix = [[0] * (len2 + 1) for _ in range(len1 + 1)]
        
                    # Initialize the first row and column of the matrix
                    for i in range(len1 + 1):
                        matrix[i][0] = i
                    for j in range(len2 + 1):
                        matrix[0][j] = j
        
                    # Populate the matrix
                    for i in range(1, len1 + 1):
                        for j in range(1, len2 + 1):
                            cost = 0 if str_value[i - 1] == reg_encoder_entries[0][0][y][j - 1] else 1
                            matrix[i][j] = min(
                                matrix[i - 1][j] + 1,        # Deletion
                                matrix[i][j - 1] + 1,        # Insertion
                                matrix[i - 1][j - 1] + cost  # Substitution
                            )
                    sim_large = matrix[len1][len2]
                    if(sim_large > max_value):
                        max_value = sim_large
                #print(max_value)
                #similarity = Levenshtein.ratio(str_value, self._registry_similar_string)
                transfor_sim_bin = '{0:016b}'.format(max_value)
                #print(transfor_sim_bin)
                for j in range(0,len(transfor_sim_bin)):
                    registry_feature[j] = transfor_sim_bin[j]
                #print("the registry feature is:",registry_feature)    
                # registry_feature += self.registry_encoder.transform([[str_value]]).reshape(-1)
                # print("the registry feature is:",registry_feature)
                #print("the size of the reg feature is ", registry_feature.shape)
            elif self._urls.match(str_value):
                max_value = -1
                for y in range(0,len(url_encoder_entries[0][0])):
                    len1, len2 = len(str_value), len(url_encoder_entries[0][0][y])
        
       
                    matrix = [[0] * (len2 + 1) for _ in range(len1 + 1)]
        
                    # Initialize the first row and column of the matrix
                    for i in range(len1 + 1):
                        matrix[i][0] = i
                    for j in range(len2 + 1):
                        matrix[0][j] = j
        
                    # Populate the matrix
                    for i in range(1, len1 + 1):
                        for j in range(1, len2 + 1):
                            cost = 0 if str_value[i - 1] == url_encoder_entries[0][0][y][j - 1] else 1
                            matrix[i][j] = min(
                                matrix[i - 1][j] + 1,        # Deletion
                                matrix[i][j - 1] + 1,        # Insertion
                                matrix[i - 1][j - 1] + cost  # Substitution
                            )
                    sim_large = matrix[len1][len2]
                    if(sim_large > max_value):
                        max_value = sim_large
                #print(max_value)
                #similarity = Levenshtein.ratio(str_value, self._registry_similar_string)
                transfor_sim_bin = '{0:016b}'.format(max_value)
                #print(transfor_sim_bin)
                for j in range(0,len(transfor_sim_bin)):
                    urls_feature[j] = transfor_sim_bin[j]
            elif self._ips.match(str_value):
                max_value = -1
                for y in range(0,len(ip_encoder_entries[0][0])):
                    len1, len2 = len(str_value), len(ip_encoder_entries[0][0][y])
        
       
                    matrix = [[0] * (len2 + 1) for _ in range(len1 + 1)]
        
                    # Initialize the first row and column of the matrix
                    for i in range(len1 + 1):
                        matrix[i][0] = i
                    for j in range(len2 + 1):
                        matrix[0][j] = j
        
                    # Populate the matrix
                    for i in range(1, len1 + 1):
                        for j in range(1, len2 + 1):
                            cost = 0 if str_value[i - 1] == ip_encoder_entries[0][0][y][j - 1] else 1
                            matrix[i][j] = min(
                                matrix[i - 1][j] + 1,        # Deletion
                                matrix[i][j - 1] + 1,        # Insertion
                                matrix[i - 1][j - 1] + cost  # Substitution
                            )
                    sim_large = matrix[len1][len2]
                    if(sim_large > max_value):
                        max_value = sim_large
                #print(max_value)
                #similarity = Levenshtein.ratio(str_value, self._registry_similar_string)
                transfor_sim_bin = '{0:016b}'.format(max_value)
                #print(transfor_sim_bin)
                for j in range(0,len(transfor_sim_bin)):
                    ips_feature[j] = transfor_sim_bin[j]

        return np.hstack([paths_feature, dlls_feature, registry_feature, urls_feature, ips_feature]).astype(np.float32)

    def process_raw_features(self, raw_obj):
        return raw_obj


# In[279]:


class ArgStrSInfo(FeatureType):
    ''' Other printable strings info '''

    name = 'strs'
    dim = 4

    def __init__(self):
        super(FeatureType, self).__init__()
        self._allstrings = re.compile(b'[\x20-\x7f]{5,}')
        self._mz = re.compile(b'MZ')
        super(FeatureType, self).__init__()

    def raw_features(self, input_dict):
        bytez = '\x11'.join(input_dict.values()).encode('UTF-8', 'ignore')
        allstrings = self._allstrings.findall(bytez)
        if allstrings:
            # statistics about strings:
            string_lengths = [len(s) for s in allstrings]
            avlength = sum(string_lengths) / len(string_lengths)
            # map printable characters 0x20 - 0x7f to an int array consisting of 0-95, inclusive
            as_shifted_string = [b - ord(b'\x20') for b in b''.join(allstrings)]
            c = np.bincount(as_shifted_string, minlength=96)  # histogram count
            # distribution of characters in printable strings
            csum = c.sum()
            p = c.astype(np.float32) / csum
            wh = np.where(c)[0]
            H = np.sum(-p[wh] * np.log2(p[wh]))  # entropy
        else:
            avlength = 0
            c = np.zeros((96,), dtype=np.float32)
            H = 0
            csum = 0
        return {
            'numstrings': len(allstrings),
            'avlength': avlength,
            'entropy': float(H),
            'MZ': len(self._mz.findall(bytez))
        }

    def process_raw_features(self, raw_obj):
        return np.hstack([raw_obj['numstrings'], raw_obj['avlength'], raw_obj['entropy'], raw_obj['MZ']]).astype(
            np.float32)


# In[280]:

procs_dup= []
call_signs =[]
arg_int_dict1, arg_str_dict1 = [], []
arguments1 = []
api_n = []
api_calls_details =[]

features_dict =[]

list_of_calls = []
len(np.unique(api_calls_details))

arg_string_dictionary = []
input_dict = {}

class CuckooReportEncoding(object):

    def __init__(self, file_md5, input_path, output_path, max_len):
        self.file_md5 = file_md5
        self.input_path = input_path
        self.output_path = output_path
        self.max_len = max_len
        self.features = dict((fe.name, fe) for fe in [APIName(), ArgIntInfo(), ArgPDRUIInfo(), ArgStrSInfo()])
        features_dict.append(self.features)
        self.data = []  # Save the encoded data of this cuckoo report

    def extract_features_for_classification(self):
        f = open(self.input_path)
        t = json.load(f)
        procs = t['behavior']['processes']
        procs_dup.append(procs)
        counter = 0
        for proc in procs:
            
            calls = proc['calls']
            list_of_calls.append(calls)
            #print("calls",calls)
            previous_hashed = ""
            for call in calls:
                #print("the value of data is", len(self.data))
                if len(self.data) >= self.max_len:
                    counter = counter + 1
                    #print("count value", counter)
                    return True
                if 'api' not in call:
                    continue
                if call['api'][:2] == '__':
                    continue
                if 'arguments' not in call:
                    call['arguments'] = {}
                if 'category' not in call:
                    call['category'] = ""
                if 'status' not in call:
                    call['status'] = 0
                api = call['api']  # api_name
                #print("the name of api",api)
                arguments = call['arguments']  # api arguments
                arguments1.append(arguments)
                call_sign = api + "-" + str(arguments)
                call_signs.append(call_sign)
                current_hashed = hashlib.md5(call_sign.encode()).hexdigest()
                
                
                if previous_hashed == current_hashed:
                    continue
                else:
                    previous_hashed = current_hashed
                # feature extraction
                # api_name
                api_name_feature = self.features['api_name'].feature_vector(api)  # word2vec encoding
                # It contains the embedding of the api_call in distinct dictionary
                api_n.append(api_name_feature)
                # str_arguments
                arg_int_dict, arg_str_dict = {}, {}
                for key, value in arguments.items():
                    if isinstance(value, (list, dict, tuple)):
                        print("came here")
                        continue
                    if isinstance(value, (int, float)):
                        arg_int_dict[key] = np.log(np.abs(value) + 1)
                    else:
                        if value is None:
                            continue
                        elif value[:2] == '0x':
                            continue
                        else:
                            arg_str_dict[key] = value
                            
                arg_int_dict1.append(arg_int_dict)
                arg_str_dict1.append(arg_str_dict)
                #print("arginit",arg_int_dict)
                #print("arg_str_dict",arg_str_dict)
                try:
                    arg_int_feature = self.features['int'].feature_vector(arg_int_dict)  # hash trick encoding
                    arg_pdrui_feature = self.features['pdrui'].feature_vector(arg_str_dict)  # similarity encoding
                    arg_string_dictionary = arg_str_dict
                    arg_strs_feature = self.features['strs'].feature_vector(arg_str_dict)  # statistics encoding
                    api_feature = np.hstack(
                        [api_name_feature, arg_int_feature, arg_pdrui_feature, arg_strs_feature]).astype(np.float32)
                    # print(api_feature)
                    self.data.append(api_feature)
                except Exception as e:
                    logging.error("api error: %s" % e)
                    pass

        return True
    
    def save(self):
        np.savez(self.output_path + self.file_md5, data=self.data)
        return True


# In[273]:


if __name__ == '__main__':
    output_path = r'C:\Users\ashish\Desktop\DMalNet-main\DMalNet-main\data\sequence\downloader\\'  # path of the encoded feature vectors
    progress_file_path = r'C:\Users\ashish\Desktop\DMalNet-main\DMalNet-main\cuckoo_report\mal\downloader\progress.txt'  # path to store the progress
    
    max_len = 1000
    
    try:
        with open(progress_file_path, 'r') as progress_file:
            processed_files = set(progress_file.read().splitlines())
    except FileNotFoundError:
        processed_files = set()
    
    json_files_directory = r'C:\Users\ashish\Desktop\DMalNet-main\DMalNet-main\cuckoo_report\mal\downloader\\'
    
    for file_number in range(1,12000):
        json_file_path = os.path.join(json_files_directory, f"{file_number}.json")
    
        if json_file_path in processed_files:
            print(f"File {json_file_path} already processed. Skipping.")
            continue
    
        if os.path.exists(json_file_path):     
            try:
                # Load the JSON data from the file
                with open(json_file_path, 'r') as json_file:
                    data = json.load(json_file)
    
                # Extract the MD5 hash from the "target" field
                file_md5 = data.get('target', {}).get('file', {}).get('md5', None)
    
                input_path = json_file_path  # path of the cuckoo report
                output_file_path = os.path.join(output_path)  # path for saving encoded feature vectors
    
                cuckoo_report_encoding = CuckooReportEncoding(file_md5, input_path, output_file_path, max_len)
    
    
    
                if cuckoo_report_encoding.extract_features_for_classification():
                    cuckoo_report_encoding.save()
    
    
    
                print(f"Processed {json_file_path}")
    
                # Record progress
                processed_files.add(json_file_path)
                
                  
                
                with open(progress_file_path, 'a') as progress_file:
                    progress_file.write(f"{json_file_path}\n")
    
            except Exception as e:
                print(f"Error processing {json_file_path}: {str(e)}")
        else:
            print(f"File {json_file_path} does not exist. Skipping.")
    
                